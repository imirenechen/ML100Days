{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 試比較 save_best_only 與否的差異\n",
    "2. 請僅存入將 save_weights_only 設定為 True, 並嘗試 reset ipynb 並將模型與權重重新建回並預測 x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 6s 24ms/step - loss: 1.8798 - accuracy: 0.3536 - val_loss: 1.7839 - val_accuracy: 0.3580\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.5546 - accuracy: 0.4531 - val_loss: 1.6326 - val_accuracy: 0.4208\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.4458 - accuracy: 0.4920 - val_loss: 1.5637 - val_accuracy: 0.4449\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.3692 - accuracy: 0.5197 - val_loss: 1.5640 - val_accuracy: 0.4509\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 1.3086 - accuracy: 0.5400 - val_loss: 1.4907 - val_accuracy: 0.4773\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 1.2555 - accuracy: 0.5600 - val_loss: 1.5004 - val_accuracy: 0.4765\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.2069 - accuracy: 0.5799 - val_loss: 1.5166 - val_accuracy: 0.4707\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.1630 - accuracy: 0.5937 - val_loss: 1.5010 - val_accuracy: 0.4716\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.1200 - accuracy: 0.6099 - val_loss: 1.4849 - val_accuracy: 0.4826\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 5s 23ms/step - loss: 1.0804 - accuracy: 0.6254 - val_loss: 1.4975 - val_accuracy: 0.4881\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 1.0437 - accuracy: 0.6374 - val_loss: 1.5005 - val_accuracy: 0.4784\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.0050 - accuracy: 0.6531 - val_loss: 1.6522 - val_accuracy: 0.4568\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 0.9733 - accuracy: 0.6646 - val_loss: 1.4975 - val_accuracy: 0.4918\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 0.9403 - accuracy: 0.6750 - val_loss: 1.5391 - val_accuracy: 0.4748\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 0.9029 - accuracy: 0.6918 - val_loss: 1.5445 - val_accuracy: 0.4805\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 0.8703 - accuracy: 0.7011 - val_loss: 1.7124 - val_accuracy: 0.4653\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.8418 - accuracy: 0.7103 - val_loss: 1.5663 - val_accuracy: 0.4797\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 0.8082 - accuracy: 0.7231 - val_loss: 1.5548 - val_accuracy: 0.4889\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.7734 - accuracy: 0.7365 - val_loss: 1.6229 - val_accuracy: 0.4772\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.7469 - accuracy: 0.7475 - val_loss: 1.6339 - val_accuracy: 0.4828\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.7169 - accuracy: 0.7591 - val_loss: 1.6994 - val_accuracy: 0.4794\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.6885 - accuracy: 0.7688 - val_loss: 1.7404 - val_accuracy: 0.4595\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.6640 - accuracy: 0.7776 - val_loss: 1.6993 - val_accuracy: 0.4761\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.6305 - accuracy: 0.7901 - val_loss: 1.8434 - val_accuracy: 0.4592\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.6048 - accuracy: 0.7989 - val_loss: 1.7307 - val_accuracy: 0.4767\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.5798 - accuracy: 0.8065 - val_loss: 1.7401 - val_accuracy: 0.4768\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 0.5546 - accuracy: 0.8163 - val_loss: 1.8608 - val_accuracy: 0.4772\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 0.5269 - accuracy: 0.8277 - val_loss: 1.9936 - val_accuracy: 0.4327\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 0.5143 - accuracy: 0.8299 - val_loss: 1.8849 - val_accuracy: 0.4614\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 6s 33ms/step - loss: 0.4830 - accuracy: 0.8435 - val_loss: 1.8993 - val_accuracy: 0.4645\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 6s 33ms/step - loss: 0.4560 - accuracy: 0.8542 - val_loss: 1.8811 - val_accuracy: 0.4709\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 0.4360 - accuracy: 0.8594 - val_loss: 1.9159 - val_accuracy: 0.4686\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 0.4181 - accuracy: 0.8659 - val_loss: 1.9484 - val_accuracy: 0.4837\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 0.3972 - accuracy: 0.8742 - val_loss: 1.9992 - val_accuracy: 0.4776\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.3709 - accuracy: 0.8826 - val_loss: 1.9783 - val_accuracy: 0.4713\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.3550 - accuracy: 0.8893 - val_loss: 2.1593 - val_accuracy: 0.4577\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 0.3396 - accuracy: 0.8941 - val_loss: 2.0194 - val_accuracy: 0.4699\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 0.3198 - accuracy: 0.9043 - val_loss: 2.0746 - val_accuracy: 0.4601\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.3026 - accuracy: 0.9078 - val_loss: 2.0704 - val_accuracy: 0.4779\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 0.2844 - accuracy: 0.9149 - val_loss: 2.2960 - val_accuracy: 0.4639\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 0.2741 - accuracy: 0.9188 - val_loss: 2.2764 - val_accuracy: 0.4598\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 0.2506 - accuracy: 0.9283 - val_loss: 2.5807 - val_accuracy: 0.4319\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 0.2438 - accuracy: 0.9286 - val_loss: 2.1879 - val_accuracy: 0.4721\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 0.2238 - accuracy: 0.9366 - val_loss: 2.2507 - val_accuracy: 0.4759\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 0.2220 - accuracy: 0.9361 - val_loss: 2.5070 - val_accuracy: 0.4578\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 8s 39ms/step - loss: 0.2125 - accuracy: 0.9395 - val_loss: 2.5656 - val_accuracy: 0.4632\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 8s 40ms/step - loss: 0.1977 - accuracy: 0.9455 - val_loss: 2.3810 - val_accuracy: 0.4683\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 0.1860 - accuracy: 0.9482 - val_loss: 2.4628 - val_accuracy: 0.4603\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 0.1776 - accuracy: 0.9514 - val_loss: 2.3947 - val_accuracy: 0.4684\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 0.1659 - accuracy: 0.9560 - val_loss: 2.5095 - val_accuracy: 0.4656\n",
      "313/313 [==============================] - 2s 6ms/step\n",
      "313/313 [==============================] - 2s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# 載入 Callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath=\"./tmp.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=True)\n",
    "\n",
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[model_ckpt]\n",
    "         )\n",
    "\n",
    "model.save(\"final_model.h5\")\n",
    "model.save_weights(\"model_weights.h5\")\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"accuracy\"]\n",
    "valid_acc = model.history.history[\"val_accuracy\"]\n",
    "\n",
    "pred_final = model.predict(x_test)\n",
    "# Load back\n",
    "model = keras.models.load_model(\"./tmp.h5\")\n",
    "pred_loadback = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of final weights: 0.466\n",
      "Accuracy of best weights: 0.483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "final_model_acc = accuracy_score(y_true=y_test.argmax(axis=-1), y_pred=pred_final.argmax(axis=-1))\n",
    "loadback_acc = accuracy_score(y_true=y_test.argmax(axis=-1), y_pred=pred_loadback.argmax(axis=-1))\n",
    "\n",
    "print(\"Accuracy of final weights: %.3f\" % final_model_acc)\n",
    "print(\"Accuracy of best weights: %.3f\" % loadback_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 6s 22ms/step - loss: 1.8785 - accuracy: 0.3628 - val_loss: 1.7592 - val_accuracy: 0.3760\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.5509 - accuracy: 0.4574 - val_loss: 1.6010 - val_accuracy: 0.4370\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.4490 - accuracy: 0.4907 - val_loss: 1.5468 - val_accuracy: 0.4542\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 4s 23ms/step - loss: 1.3776 - accuracy: 0.5169 - val_loss: 1.5469 - val_accuracy: 0.4482\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 4s 21ms/step - loss: 1.3155 - accuracy: 0.5387 - val_loss: 1.5031 - val_accuracy: 0.4752\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.2649 - accuracy: 0.5583 - val_loss: 1.4960 - val_accuracy: 0.4689\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 4s 22ms/step - loss: 1.2166 - accuracy: 0.5728 - val_loss: 1.5050 - val_accuracy: 0.4735\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.1737 - accuracy: 0.5886 - val_loss: 1.5061 - val_accuracy: 0.4671\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 1.1297 - accuracy: 0.6051 - val_loss: 1.5043 - val_accuracy: 0.4783\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.0939 - accuracy: 0.6183 - val_loss: 1.4685 - val_accuracy: 0.4854\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 6s 29ms/step - loss: 1.0556 - accuracy: 0.6309 - val_loss: 1.5651 - val_accuracy: 0.4607\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 6s 29ms/step - loss: 1.0206 - accuracy: 0.6452 - val_loss: 1.4937 - val_accuracy: 0.4808\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 6s 29ms/step - loss: 0.9839 - accuracy: 0.6575 - val_loss: 1.5588 - val_accuracy: 0.4701\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 0.9490 - accuracy: 0.6720 - val_loss: 1.5774 - val_accuracy: 0.4677\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.9138 - accuracy: 0.6841 - val_loss: 1.5306 - val_accuracy: 0.4792\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.8842 - accuracy: 0.6955 - val_loss: 1.6655 - val_accuracy: 0.4580\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.8510 - accuracy: 0.7069 - val_loss: 1.5774 - val_accuracy: 0.4814\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 0.8190 - accuracy: 0.7190 - val_loss: 1.5867 - val_accuracy: 0.4874\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.7885 - accuracy: 0.7305 - val_loss: 1.6375 - val_accuracy: 0.4765\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.7595 - accuracy: 0.7396 - val_loss: 1.7251 - val_accuracy: 0.4670\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 0.7286 - accuracy: 0.7528 - val_loss: 1.7308 - val_accuracy: 0.4648\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 0.7021 - accuracy: 0.7629 - val_loss: 1.7000 - val_accuracy: 0.4830\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 0.6686 - accuracy: 0.7740 - val_loss: 1.6851 - val_accuracy: 0.4769\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 0.6406 - accuracy: 0.7853 - val_loss: 1.6501 - val_accuracy: 0.4805\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 7s 34ms/step - loss: 0.6165 - accuracy: 0.7941 - val_loss: 1.7697 - val_accuracy: 0.4696\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 7s 35ms/step - loss: 0.5914 - accuracy: 0.8025 - val_loss: 1.7696 - val_accuracy: 0.4720\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.5612 - accuracy: 0.8141 - val_loss: 1.8001 - val_accuracy: 0.4650\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 0.5392 - accuracy: 0.8214 - val_loss: 1.8705 - val_accuracy: 0.4549\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 7s 36ms/step - loss: 0.5140 - accuracy: 0.8304 - val_loss: 1.8467 - val_accuracy: 0.4582\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.4917 - accuracy: 0.8385 - val_loss: 1.8986 - val_accuracy: 0.4676\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 7s 38ms/step - loss: 0.4652 - accuracy: 0.8498 - val_loss: 1.9053 - val_accuracy: 0.4572\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 8s 39ms/step - loss: 0.4377 - accuracy: 0.8589 - val_loss: 2.1723 - val_accuracy: 0.4611\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 0.4180 - accuracy: 0.8668 - val_loss: 2.1295 - val_accuracy: 0.4460\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 0.4014 - accuracy: 0.8725 - val_loss: 2.0579 - val_accuracy: 0.4463\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 0.3798 - accuracy: 0.8795 - val_loss: 1.9865 - val_accuracy: 0.4629\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 0.3617 - accuracy: 0.8860 - val_loss: 2.1433 - val_accuracy: 0.4780\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 9s 43ms/step - loss: 0.3402 - accuracy: 0.8950 - val_loss: 2.1980 - val_accuracy: 0.4552\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 0.3232 - accuracy: 0.9011 - val_loss: 2.1695 - val_accuracy: 0.4646\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 0.3089 - accuracy: 0.9054 - val_loss: 2.1502 - val_accuracy: 0.4668\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 0.2954 - accuracy: 0.9105 - val_loss: 2.2084 - val_accuracy: 0.4714\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 9s 43ms/step - loss: 0.2840 - accuracy: 0.9138 - val_loss: 2.3213 - val_accuracy: 0.4479\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 0.2751 - accuracy: 0.9160 - val_loss: 2.2528 - val_accuracy: 0.4487\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 0.2618 - accuracy: 0.9212 - val_loss: 2.2800 - val_accuracy: 0.4745\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 8s 43ms/step - loss: 0.2513 - accuracy: 0.9250 - val_loss: 2.2477 - val_accuracy: 0.4756\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 0.2206 - accuracy: 0.9371 - val_loss: 2.3625 - val_accuracy: 0.4599\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 5s 26ms/step - loss: 0.2149 - accuracy: 0.9375 - val_loss: 2.2630 - val_accuracy: 0.4787\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 0.1977 - accuracy: 0.9449 - val_loss: 2.3033 - val_accuracy: 0.4679\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 0.1860 - accuracy: 0.9490 - val_loss: 2.3487 - val_accuracy: 0.4700\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 0.1788 - accuracy: 0.9508 - val_loss: 2.4719 - val_accuracy: 0.4627\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 0.1750 - accuracy: 0.9528 - val_loss: 2.4258 - val_accuracy: 0.4650\n",
      "313/313 [==============================] - 2s 6ms/step\n",
      "313/313 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath=\"./tmp.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=False)\n",
    "\n",
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[model_ckpt]\n",
    "         )\n",
    "\n",
    "model.save(\"final_model.h5\")\n",
    "model.save_weights(\"model_weights.h5\")\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"accuracy\"]\n",
    "valid_acc = model.history.history[\"val_accuracy\"]\n",
    "\n",
    "pred_final = model.predict(x_test)\n",
    "# Load back\n",
    "model = keras.models.load_model(\"./tmp.h5\")\n",
    "pred_loadback = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of final weights: 0.465\n",
      "Accuracy of best weights: 0.465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "final_model_acc = accuracy_score(y_true=y_test.argmax(axis=-1), y_pred=pred_final.argmax(axis=-1))\n",
    "loadback_acc = accuracy_score(y_true=y_test.argmax(axis=-1), y_pred=pred_loadback.argmax(axis=-1))\n",
    "\n",
    "print(\"Accuracy of final weights: %.3f\" % final_model_acc)\n",
    "print(\"Accuracy of best weights: %.3f\" % loadback_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筆記\n",
    "- save_best_only 若為 False 就是儲存最後的結果而不是最好的，所以使用 Model check point 就把 save_best_only 打開"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
